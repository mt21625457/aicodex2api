// Code generated by ent, DO NOT EDIT.

package ent

import (
	"fmt"
	"strings"
	"time"

	"entgo.io/ent"
	"entgo.io/ent/dialect/sql"
	"github.com/Wei-Shaw/sub2api/backup/ent/backupjob"
)

// BackupJob is the model entity for the BackupJob schema.
type BackupJob struct {
	config `json:"-"`
	// ID of the ent.
	ID int `json:"id,omitempty"`
	// JobID holds the value of the "job_id" field.
	JobID string `json:"job_id,omitempty"`
	// BackupType holds the value of the "backup_type" field.
	BackupType backupjob.BackupType `json:"backup_type,omitempty"`
	// Status holds the value of the "status" field.
	Status backupjob.Status `json:"status,omitempty"`
	// TriggeredBy holds the value of the "triggered_by" field.
	TriggeredBy string `json:"triggered_by,omitempty"`
	// IdempotencyKey holds the value of the "idempotency_key" field.
	IdempotencyKey string `json:"idempotency_key,omitempty"`
	// UploadToS3 holds the value of the "upload_to_s3" field.
	UploadToS3 bool `json:"upload_to_s3,omitempty"`
	// StartedAt holds the value of the "started_at" field.
	StartedAt *time.Time `json:"started_at,omitempty"`
	// FinishedAt holds the value of the "finished_at" field.
	FinishedAt *time.Time `json:"finished_at,omitempty"`
	// ErrorMessage holds the value of the "error_message" field.
	ErrorMessage string `json:"error_message,omitempty"`
	// ArtifactLocalPath holds the value of the "artifact_local_path" field.
	ArtifactLocalPath string `json:"artifact_local_path,omitempty"`
	// ArtifactSizeBytes holds the value of the "artifact_size_bytes" field.
	ArtifactSizeBytes *int64 `json:"artifact_size_bytes,omitempty"`
	// ArtifactSha256 holds the value of the "artifact_sha256" field.
	ArtifactSha256 string `json:"artifact_sha256,omitempty"`
	// S3Bucket holds the value of the "s3_bucket" field.
	S3Bucket string `json:"s3_bucket,omitempty"`
	// S3Key holds the value of the "s3_key" field.
	S3Key string `json:"s3_key,omitempty"`
	// S3Etag holds the value of the "s3_etag" field.
	S3Etag string `json:"s3_etag,omitempty"`
	// CreatedAt holds the value of the "created_at" field.
	CreatedAt time.Time `json:"created_at,omitempty"`
	// UpdatedAt holds the value of the "updated_at" field.
	UpdatedAt time.Time `json:"updated_at,omitempty"`
	// Edges holds the relations/edges for other nodes in the graph.
	// The values are being populated by the BackupJobQuery when eager-loading is set.
	Edges        BackupJobEdges `json:"edges"`
	selectValues sql.SelectValues
}

// BackupJobEdges holds the relations/edges for other nodes in the graph.
type BackupJobEdges struct {
	// Events holds the value of the events edge.
	Events []*BackupJobEvent `json:"events,omitempty"`
	// loadedTypes holds the information for reporting if a
	// type was loaded (or requested) in eager-loading or not.
	loadedTypes [1]bool
}

// EventsOrErr returns the Events value or an error if the edge
// was not loaded in eager-loading.
func (e BackupJobEdges) EventsOrErr() ([]*BackupJobEvent, error) {
	if e.loadedTypes[0] {
		return e.Events, nil
	}
	return nil, &NotLoadedError{edge: "events"}
}

// scanValues returns the types for scanning values from sql.Rows.
func (*BackupJob) scanValues(columns []string) ([]any, error) {
	values := make([]any, len(columns))
	for i := range columns {
		switch columns[i] {
		case backupjob.FieldUploadToS3:
			values[i] = new(sql.NullBool)
		case backupjob.FieldID, backupjob.FieldArtifactSizeBytes:
			values[i] = new(sql.NullInt64)
		case backupjob.FieldJobID, backupjob.FieldBackupType, backupjob.FieldStatus, backupjob.FieldTriggeredBy, backupjob.FieldIdempotencyKey, backupjob.FieldErrorMessage, backupjob.FieldArtifactLocalPath, backupjob.FieldArtifactSha256, backupjob.FieldS3Bucket, backupjob.FieldS3Key, backupjob.FieldS3Etag:
			values[i] = new(sql.NullString)
		case backupjob.FieldStartedAt, backupjob.FieldFinishedAt, backupjob.FieldCreatedAt, backupjob.FieldUpdatedAt:
			values[i] = new(sql.NullTime)
		default:
			values[i] = new(sql.UnknownType)
		}
	}
	return values, nil
}

// assignValues assigns the values that were returned from sql.Rows (after scanning)
// to the BackupJob fields.
func (_m *BackupJob) assignValues(columns []string, values []any) error {
	if m, n := len(values), len(columns); m < n {
		return fmt.Errorf("mismatch number of scan values: %d != %d", m, n)
	}
	for i := range columns {
		switch columns[i] {
		case backupjob.FieldID:
			value, ok := values[i].(*sql.NullInt64)
			if !ok {
				return fmt.Errorf("unexpected type %T for field id", value)
			}
			_m.ID = int(value.Int64)
		case backupjob.FieldJobID:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field job_id", values[i])
			} else if value.Valid {
				_m.JobID = value.String
			}
		case backupjob.FieldBackupType:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field backup_type", values[i])
			} else if value.Valid {
				_m.BackupType = backupjob.BackupType(value.String)
			}
		case backupjob.FieldStatus:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field status", values[i])
			} else if value.Valid {
				_m.Status = backupjob.Status(value.String)
			}
		case backupjob.FieldTriggeredBy:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field triggered_by", values[i])
			} else if value.Valid {
				_m.TriggeredBy = value.String
			}
		case backupjob.FieldIdempotencyKey:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field idempotency_key", values[i])
			} else if value.Valid {
				_m.IdempotencyKey = value.String
			}
		case backupjob.FieldUploadToS3:
			if value, ok := values[i].(*sql.NullBool); !ok {
				return fmt.Errorf("unexpected type %T for field upload_to_s3", values[i])
			} else if value.Valid {
				_m.UploadToS3 = value.Bool
			}
		case backupjob.FieldStartedAt:
			if value, ok := values[i].(*sql.NullTime); !ok {
				return fmt.Errorf("unexpected type %T for field started_at", values[i])
			} else if value.Valid {
				_m.StartedAt = new(time.Time)
				*_m.StartedAt = value.Time
			}
		case backupjob.FieldFinishedAt:
			if value, ok := values[i].(*sql.NullTime); !ok {
				return fmt.Errorf("unexpected type %T for field finished_at", values[i])
			} else if value.Valid {
				_m.FinishedAt = new(time.Time)
				*_m.FinishedAt = value.Time
			}
		case backupjob.FieldErrorMessage:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field error_message", values[i])
			} else if value.Valid {
				_m.ErrorMessage = value.String
			}
		case backupjob.FieldArtifactLocalPath:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field artifact_local_path", values[i])
			} else if value.Valid {
				_m.ArtifactLocalPath = value.String
			}
		case backupjob.FieldArtifactSizeBytes:
			if value, ok := values[i].(*sql.NullInt64); !ok {
				return fmt.Errorf("unexpected type %T for field artifact_size_bytes", values[i])
			} else if value.Valid {
				_m.ArtifactSizeBytes = new(int64)
				*_m.ArtifactSizeBytes = value.Int64
			}
		case backupjob.FieldArtifactSha256:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field artifact_sha256", values[i])
			} else if value.Valid {
				_m.ArtifactSha256 = value.String
			}
		case backupjob.FieldS3Bucket:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field s3_bucket", values[i])
			} else if value.Valid {
				_m.S3Bucket = value.String
			}
		case backupjob.FieldS3Key:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field s3_key", values[i])
			} else if value.Valid {
				_m.S3Key = value.String
			}
		case backupjob.FieldS3Etag:
			if value, ok := values[i].(*sql.NullString); !ok {
				return fmt.Errorf("unexpected type %T for field s3_etag", values[i])
			} else if value.Valid {
				_m.S3Etag = value.String
			}
		case backupjob.FieldCreatedAt:
			if value, ok := values[i].(*sql.NullTime); !ok {
				return fmt.Errorf("unexpected type %T for field created_at", values[i])
			} else if value.Valid {
				_m.CreatedAt = value.Time
			}
		case backupjob.FieldUpdatedAt:
			if value, ok := values[i].(*sql.NullTime); !ok {
				return fmt.Errorf("unexpected type %T for field updated_at", values[i])
			} else if value.Valid {
				_m.UpdatedAt = value.Time
			}
		default:
			_m.selectValues.Set(columns[i], values[i])
		}
	}
	return nil
}

// Value returns the ent.Value that was dynamically selected and assigned to the BackupJob.
// This includes values selected through modifiers, order, etc.
func (_m *BackupJob) Value(name string) (ent.Value, error) {
	return _m.selectValues.Get(name)
}

// QueryEvents queries the "events" edge of the BackupJob entity.
func (_m *BackupJob) QueryEvents() *BackupJobEventQuery {
	return NewBackupJobClient(_m.config).QueryEvents(_m)
}

// Update returns a builder for updating this BackupJob.
// Note that you need to call BackupJob.Unwrap() before calling this method if this BackupJob
// was returned from a transaction, and the transaction was committed or rolled back.
func (_m *BackupJob) Update() *BackupJobUpdateOne {
	return NewBackupJobClient(_m.config).UpdateOne(_m)
}

// Unwrap unwraps the BackupJob entity that was returned from a transaction after it was closed,
// so that all future queries will be executed through the driver which created the transaction.
func (_m *BackupJob) Unwrap() *BackupJob {
	_tx, ok := _m.config.driver.(*txDriver)
	if !ok {
		panic("ent: BackupJob is not a transactional entity")
	}
	_m.config.driver = _tx.drv
	return _m
}

// String implements the fmt.Stringer.
func (_m *BackupJob) String() string {
	var builder strings.Builder
	builder.WriteString("BackupJob(")
	builder.WriteString(fmt.Sprintf("id=%v, ", _m.ID))
	builder.WriteString("job_id=")
	builder.WriteString(_m.JobID)
	builder.WriteString(", ")
	builder.WriteString("backup_type=")
	builder.WriteString(fmt.Sprintf("%v", _m.BackupType))
	builder.WriteString(", ")
	builder.WriteString("status=")
	builder.WriteString(fmt.Sprintf("%v", _m.Status))
	builder.WriteString(", ")
	builder.WriteString("triggered_by=")
	builder.WriteString(_m.TriggeredBy)
	builder.WriteString(", ")
	builder.WriteString("idempotency_key=")
	builder.WriteString(_m.IdempotencyKey)
	builder.WriteString(", ")
	builder.WriteString("upload_to_s3=")
	builder.WriteString(fmt.Sprintf("%v", _m.UploadToS3))
	builder.WriteString(", ")
	if v := _m.StartedAt; v != nil {
		builder.WriteString("started_at=")
		builder.WriteString(v.Format(time.ANSIC))
	}
	builder.WriteString(", ")
	if v := _m.FinishedAt; v != nil {
		builder.WriteString("finished_at=")
		builder.WriteString(v.Format(time.ANSIC))
	}
	builder.WriteString(", ")
	builder.WriteString("error_message=")
	builder.WriteString(_m.ErrorMessage)
	builder.WriteString(", ")
	builder.WriteString("artifact_local_path=")
	builder.WriteString(_m.ArtifactLocalPath)
	builder.WriteString(", ")
	if v := _m.ArtifactSizeBytes; v != nil {
		builder.WriteString("artifact_size_bytes=")
		builder.WriteString(fmt.Sprintf("%v", *v))
	}
	builder.WriteString(", ")
	builder.WriteString("artifact_sha256=")
	builder.WriteString(_m.ArtifactSha256)
	builder.WriteString(", ")
	builder.WriteString("s3_bucket=")
	builder.WriteString(_m.S3Bucket)
	builder.WriteString(", ")
	builder.WriteString("s3_key=")
	builder.WriteString(_m.S3Key)
	builder.WriteString(", ")
	builder.WriteString("s3_etag=")
	builder.WriteString(_m.S3Etag)
	builder.WriteString(", ")
	builder.WriteString("created_at=")
	builder.WriteString(_m.CreatedAt.Format(time.ANSIC))
	builder.WriteString(", ")
	builder.WriteString("updated_at=")
	builder.WriteString(_m.UpdatedAt.Format(time.ANSIC))
	builder.WriteByte(')')
	return builder.String()
}

// BackupJobs is a parsable slice of BackupJob.
type BackupJobs []*BackupJob
