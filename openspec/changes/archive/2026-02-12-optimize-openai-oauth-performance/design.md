## Context

当前 OpenAI OAuth 主链路为：`Codex CLI/VSCode` 发起 `POST /v1/responses`，经 API Key 认证、并发控制、账号调度、OAuth token 获取后转发到 `chatgpt.com/backend-api/codex/responses`（或 OpenAI 平台接口），并将 SSE/JSON 回传客户端。

在当前实现中，性能开销主要集中在四个层面：

- 请求热路径：同一请求体在 handler/service 中存在多次解析与拷贝，且有非必要上下文写入。
- 并发与调度路径：常态请求存在额外 Redis 往返，且部分释放逻辑引入请求级 goroutine 开销。
- 流式转发路径：SSE 逐行处理中存在正则匹配、重复字符串处理与频繁 JSON 解析，导致 CPU 与 GC 压力增大。
- token 路径：锁竞争时的固定等待策略放大尾延迟。

约束条件：

- 对外 API 协议和行为保持兼容（包括 OpenAI Responses 流式语义）。
- 优先优化 P95/P99 与稳定性，不以牺牲正确性/可运维性换取短期吞吐。
- 优化必须可观测、可灰度、可回滚。

## Goals / Non-Goals

**Goals:**

- 建立 OpenAI OAuth 路径统一性能目标：网关附加延迟、TTFT、P95/P99、错误率、CPU 与内存分配。
- 将常态请求中的非必要 Redis 往返与 goroutine 开销降到最低。
- 降低 SSE 热路径 CPU/GC 成本，提升流式场景尾延迟稳定性。
- 优化 token 获取竞争路径，减少锁等待带来的请求抖动。
- 提供可量化的压测与回归基线，确保后续变更可持续守住性能红线。

**Non-Goals:**

- 不改变对外路由、请求/响应 JSON 结构与鉴权协议。
- 不在本次变更中引入新的外部基础设施（如新增 MQ、新增缓存集群）。
- 不重构全部网关模块，仅聚焦 OpenAI OAuth 高流量主路径。

## Decisions

### 决策 1：按“路径分层”进行优化，而非一次性大重构

- 选择：将优化拆为请求热路径、并发调度路径、流式路径、token 路径四类子改造，逐步落地。
- 原因：该线路跨越 handler/service/repository/config，直接大重构风险高、回滚困难。
- 备选方案：一次性重写 OpenAI gateway handler/service。
- 不选原因：改动面过大，难以定位回归，难以灰度验证单项收益。

### 决策 2：并发控制改为“先抢槽再排队”的快速路径

- 选择：优先尝试直接获取用户并发槽，失败后再进入等待计数与等待逻辑。
- 原因：当前“先加等待计数再抢槽”会让常态成功请求承担额外 Redis 往返。
- 备选方案：保留现状，仅调大 Redis 与连接池。
- 不选原因：只能缓解，不解决协议级额外操作造成的固有延迟。

### 决策 3：释放回调改为 `context.AfterFunc`/等效轻量机制

- 选择：取消每请求一个守护 goroutine 的释放模式，采用 context 生命周期回调。
- 原因：高并发流式场景中，短生命周期 goroutine 数量会放大调度与内存压力。
- 备选方案：保留 goroutine，依赖 runtime 自适应。
- 不选原因：尾延迟仍受影响，且难以精准控量。

### 决策 4：SSE 热路径去正则化与选择性解析

- 选择：SSE 行识别由正则改为前缀/状态机方式；仅对关键事件做 JSON 解析（如 `response.completed` usage），减少每行开销。
- 原因：SSE 高频循环中正则 + 字符串替换 + JSON 反序列化是热点。
- 备选方案：保留现有实现，仅通过 CPU 扩容应对。
- 不选原因：成本不可持续，且扩容无法有效压缩 P99 抖动。

### 决策 5：token 锁竞争改为短轮询+jitter，替代固定 sleep

- 选择：将锁竞争等待从固定 `200ms` 改为短间隔重试并加抖动，支持更快命中缓存刷新结果。
- 原因：固定等待会在高并发下直接拉高请求尾延迟。
- 备选方案：继续固定 sleep 并缩短数值。
- 不选原因：缺乏自适应能力，竞争抖动下仍易形成延迟台阶。

### 决策 6：观测先行，建立性能守门指标

- 选择：为该链路补齐阶段性耗时指标（认证/调度/token/上游首包/SSE 处理）与压测报告模板。
- 原因：没有统一指标就无法客观验证“极致优化”是否达标。
- 备选方案：仅通过主观体感或单一 QPS 指标评估。
- 不选原因：无法定位瓶颈迁移，也无法防止回归。

## Risks / Trade-offs

- [风险] SSE 解析策略变更可能引入协议兼容问题（尤其是边缘事件格式）  
  → Mitigation：增加真实样本回放测试；灰度期间双写校验（新旧解析结果比对）。

- [风险] 并发控制流程调整可能导致等待计数与槽位计数不一致  
  → Mitigation：增加一致性指标（槽位数、等待数、释放成功率）并设置告警。

- [风险] token 锁策略调整可能在极端场景增加刷新请求数  
  → Mitigation：保留分布式锁上限与刷新熔断策略，设置刷新 QPS 保护阈值。

- [权衡] 引入更多性能指标会增加少量埋点开销  
  → Mitigation：仅对关键路径埋点，避免高基数标签，必要时采样。

## Migration Plan

1. 基线阶段：在现网采集当前性能基线（QPS、P50/P95/P99、TTFT、错误率、CPU/内存、Redis RT）。
2. 改造阶段（分批）：
   - 批次 A：并发控制快速路径 + 释放机制优化。
   - 批次 B：SSE 热路径优化。
   - 批次 C：token 竞争路径优化。
   - 批次 D：请求体与中间件热路径微优化。
3. 灰度阶段：按实例或流量比例灰度，逐批验证收益与回归。
4. 全量阶段：达到验收指标后全量发布。
5. 回滚策略：每批次独立开关或可逆提交，异常时按批次快速回滚。

## 审核门禁（Coding Gate）

在进入编码前，以下门禁项 MUST 完成签核：

- 基线签核：确认基线采集时间窗口、压测场景、流量模型与样本数据来源。
- 目标签核：确认并冻结性能目标阈值（至少包含 P95/P99、TTFT、错误率、CPU/内存、Redis RT）。
- 发布签核：确认灰度批次、观测指标、回滚触发阈值与回滚路径。

> 说明：若上述任一门禁未签核，本变更 SHOULD NOT 进入编码阶段。

## Open Questions

- 是否需要对不同客户端类型（Codex CLI / VSCode / 其他）采用不同优化策略与阈值？
- 连接池隔离策略是否从 `account_proxy` 调整为 `proxy` 需要先在哪个环境完成风险验证？
- 目标 SLO 的最终阈值（例如网关附加 P99、TTFT）由谁签字确认，验收窗口多久？
- 是否需要将该线路纳入 CI 压测基线门禁，避免后续功能迭代带来性能回归？
